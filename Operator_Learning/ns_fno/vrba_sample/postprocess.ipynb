{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b833639-0288-4492-95d0-be410d18c848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3873133/2891255144.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from neuralop.models import TFNO3d\n",
    "\n",
    "\n",
    "# from YourDataset import YourDataset  # Import your custom dataset here\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(23)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9c249e-8d74-4cc6-9f5c-f326e88202fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom loss function here\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true, Par, Lambda=None):\n",
    "        # Implement your custom loss calculation here\n",
    "        if Lambda is not None:\n",
    "            residue = torch.absolute(y_true - y_pred)\n",
    "            Lambda = Par['gamma']*Lambda + Par['eta']*residue/torch.max(residue)\n",
    "            loss = torch.mean(torch.square(Lambda*residue)) \n",
    "        \n",
    "        else:\n",
    "            loss = torch.mean(torch.square(y_true - y_pred)) \n",
    "            # loss = torch.norm(y_true-y_pred, p=2)/torch.norm(y_true, p=2)\n",
    "\n",
    "        return loss, Lambda\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.x[idx]\n",
    "        y_sample = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x_sample, y_sample = self.transform(x_sample, y_sample)\n",
    "\n",
    "        return x_sample, y_sample\n",
    "\n",
    "class Normalizer():\n",
    "    def __init__(self, shift, scale):\n",
    "        self.shift = torch.tensor(shift, dtype=torch.float32)\n",
    "        self.scale = torch.tensor(scale, dtype=torch.float32)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return (x - self.shift)/self.scale\n",
    "    \n",
    "    def renormalize(self, x):\n",
    "        return x*self.scale + self.shift\n",
    "\n",
    "def get_xyt_grid(nx=None, ny=None, nt=None, bot=[0, 0, 0], top=[1, 1, 1], dtype='float32',\n",
    "                 x_arr=None, y_arr=None, t_arr=None, dt=0.):\n",
    "    '''\n",
    "    Args:\n",
    "        S: number of points on each spatial domain\n",
    "        T: number of points on temporal domain including endpoint\n",
    "        bot: list or tuple, lower bound on each dimension\n",
    "        top: list or tuple, upper bound on each dimension\n",
    "\n",
    "    Returns:\n",
    "        (n_x, n_y, n_t, 3) array of grid points\n",
    "    '''\n",
    "    if x_arr is None:\n",
    "        x_arr = np.linspace(bot[0], top[0], num=nx, endpoint=True)\n",
    "\n",
    "    if y_arr is None:\n",
    "        y_arr = np.linspace(bot[1], top[1], num=ny, endpoint=True)\n",
    "\n",
    "    if t_arr is None:\n",
    "        if dt is None:\n",
    "            dt = (top[2] - bot[2]) / nt\n",
    "        t_arr = np.linspace(bot[2] + dt, top[2], num=nt)\n",
    "\n",
    "    x_grid, y_grid, t_grid = np.meshgrid(x_arr, y_arr, t_arr, indexing='ij')\n",
    "    x_axis = np.ravel(x_grid)\n",
    "    y_axis = np.ravel(y_grid)\n",
    "    t_axis = np.ravel(t_grid)\n",
    "    grid = np.stack([x_axis, y_axis, t_axis], axis=0).T\n",
    "\n",
    "    x_grid, y_grid = np.meshgrid(x_arr, y_arr, indexing='ij')\n",
    "    x_axis = np.ravel(x_grid)\n",
    "    y_axis = np.ravel(y_grid)\n",
    "    grid_space = np.stack([x_axis, y_axis], axis=0).T\n",
    "\n",
    "    grids_dict = {'grid_x': x_arr, \n",
    "                  'grid_y': y_arr,\n",
    "                  'grid_t': t_arr, \n",
    "                  'grid_space': grid_space, \n",
    "                  'grid': grid}\n",
    "    for key in grids_dict.keys():\n",
    "        grids_dict[key] = torch.tensor(grids_dict[key], dtype=eval('torch.' + dtype), device='cpu')\n",
    "    return grids_dict\n",
    "\n",
    "\n",
    "\n",
    "def _preprocess_fno(data_dict, Par):\n",
    "    Grid_train = get_xyt_grid(Par['nx'], Par['ny'], Par['lf'], bot=[0, 0, 0], top=[1, 1, 1], dtype='float32')\n",
    "    Grid_test  = get_xyt_grid(Par['nx'], Par['ny'], Par['lf'], bot=[0, 0, 0], top=[1, 1, 1], dtype='float32')\n",
    "    \n",
    "    data_dim = len(data_dict['x_train'].shape) - 2\n",
    "    if data_dim != len(data_dict['x_test'].shape) - 2:\n",
    "        raise ValueError('Data dimension mismatch between train and test sets.' +\n",
    "                            f'Train: {data_dim}, Test: {len(data_dict[\"x_test\"].shape)}')\n",
    "\n",
    "    # Repeat shape is [1, time_steps_train, 1, 1, 1] for 3D data\n",
    "    time_steps_train = Par['lf'] #self.configs.time_steps_train\n",
    "    time_steps_val = Par['lf'] #self.configs.time_steps_inference if self.configs.scenario == 'hypersonics' \\\n",
    "    time_steps_test = Par['lf'] #self.configs.time_steps_inference\n",
    "    repeat_shape_train = [1, time_steps_train] + [1] * data_dim\n",
    "    repeat_shape_val = [1, time_steps_val] + [1] * data_dim\n",
    "    repeat_shape_test = [1, time_steps_test] + [1] * data_dim\n",
    "\n",
    "    data_dict['x_train'] = data_dict['x_train'].repeat(repeat_shape_train)\n",
    "    data_dict['x_val'] = data_dict['x_val'].repeat(repeat_shape_val)\n",
    "    data_dict['x_test'] = data_dict['x_test'].repeat(repeat_shape_test)\n",
    "\n",
    "  \n",
    "\n",
    "    for dataset in ['x_train', 'x_val', 'x_test']:\n",
    "        n_samples = data_dict[dataset].shape[0]\n",
    "        if True:\n",
    "            grid = Grid_test if dataset == 'x_test' else Grid_train\n",
    "            time_steps = time_steps_test if dataset == 'x_test' else time_steps_train\n",
    "\n",
    "        grid_t = grid['grid_t'].reshape([1, time_steps] + [1] * data_dim)\n",
    "        grid_t = grid_t.repeat(\n",
    "            [n_samples, 1] + list(data_dict[dataset].shape[2:]))\n",
    "        if data_dim == 1:\n",
    "            x_shape = [1, 1] + list(data_dict[dataset].shape[2:3])\n",
    "            grid_x = grid['grid_x'].reshape(\n",
    "                x_shape).repeat(n_samples, time_steps, 1)\n",
    "            data_dict[dataset] = torch.stack(\n",
    "                [data_dict[dataset], grid_x, grid_t], dim=1)\n",
    "        elif data_dim == 2:\n",
    "            x_shape = [1, 1] + list(data_dict[dataset].shape[2:3]) + [1]\n",
    "            y_shape = [1, 1, 1] + list(data_dict[dataset].shape[3:])\n",
    "\n",
    "            grid_x = grid['grid_x'].reshape(x_shape).repeat(\n",
    "                n_samples, time_steps, 1, y_shape[-1])\n",
    "            grid_y = grid['grid_y'].reshape(y_shape).repeat(\n",
    "                n_samples, time_steps, x_shape[-2], 1)\n",
    "\n",
    "            data_dict[dataset] = torch.stack(\n",
    "                [data_dict[dataset], grid_x, grid_y, grid_t], dim=1)\n",
    "        elif data_dim == 3:\n",
    "            x_shape = [1, 1] + list(data_dict[dataset].shape[2:3]) + [1, 1]\n",
    "            y_shape = [1, 1, 1] + list(data_dict[dataset].shape[3:4]) + [1]\n",
    "            z_shape = [1, 1, 1, 1] + list(data_dict[dataset].shape[4:])\n",
    "            grid_x = grid['grid_x'].reshape(x_shape)\n",
    "            grid_y = grid['grid_y'].reshape(y_shape)\n",
    "            grid_z = grid['grid_z'].reshape(z_shape)\n",
    "\n",
    "            grid_x = grid_x.repeat(\n",
    "                n_samples, time_steps, 1, y_shape[-2], z_shape[-1])\n",
    "            grid_y = grid_y.repeat(\n",
    "                n_samples, time_steps, x_shape[-3], 1, z_shape[-1])\n",
    "            grid_z = grid_z.repeat(\n",
    "                n_samples, time_steps, x_shape[-3], y_shape[-2], 1)\n",
    "\n",
    "            data_dict[dataset] = torch.stack(\n",
    "                [data_dict[dataset], grid_x, grid_y, grid_z, grid_t], dim=1)\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def preprocess(traj, Par):\n",
    "    x = sliding_window_view(traj[:,:-(Par['lf']-1),:,:], window_shape=Par['lb'], axis=1 ).transpose(0,1,4,2,3).reshape(-1,Par['lb'],Par['nx'], Par['ny'])\n",
    "    y = sliding_window_view(traj[:,Par['lb']-1:,:,:], window_shape=Par['lf'], axis=1 ).transpose(0,1,4,2,3).reshape(-1,Par['lf'],Par['nx'], Par['ny'])\n",
    "    t = np.linspace(0,1,Par['lf']).reshape(-1,1)\n",
    "\n",
    "    nt = y.shape[1]\n",
    "    n_samples = y.shape[0]\n",
    "\n",
    "    # t = np.tile(t, [n_samples,1]).reshape(-1,)                                                     #[_*nt, ]\n",
    "    # x = np.repeat(x,nt, axis=0)                                   #[_*nt, 1, 64, 64]\n",
    "    # y = y.reshape(y.shape[0]*y.shape[1],1,y.shape[2],y.shape[3])  #[_*nt, 64, 64]\n",
    "\n",
    "\n",
    "    print('x: ', x.shape)\n",
    "    print('y: ', y.shape)\n",
    "    print('t: ', t.shape)\n",
    "    print()\n",
    "    return x,y,t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16f8ddc-3e7e-472d-a8bb-f3c15b2cb356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Dataset\n",
      "x:  (800, 1, 64, 64)\n",
      "y:  (800, 51, 64, 64)\n",
      "t:  (51, 1)\n",
      "\n",
      "\n",
      "Validation Dataset\n",
      "x:  (100, 1, 64, 64)\n",
      "y:  (100, 51, 64, 64)\n",
      "t:  (51, 1)\n",
      "\n",
      "\n",
      "Test Dataset\n",
      "x:  (100, 1, 64, 64)\n",
      "y:  (100, 51, 64, 64)\n",
      "t:  (51, 1)\n",
      "\n",
      "Lambda:  (800, 51, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load your data into NumPy arrays (x_train, t_train, y_train, x_val, t_val, y_val, x_test, t_test, y_test)\n",
    "#########################\n",
    "x = np.load('../data/x.npy')  #[_, 64, 64]\n",
    "t = np.load('../data/t.npy')  #[_, 200]\n",
    "y = np.load('../data/y.npy')  #[_, 64, 64, 200]\n",
    "\n",
    "traj = np.append( np.expand_dims(x, axis=-1), y, axis=-1 ).transpose(0,3,1,2) #[_, 64, 64, 201]\n",
    "\n",
    "traj_train = traj[:800, ::4]\n",
    "traj_val   = traj[800:900, ::4]\n",
    "traj_test  = traj[900:, ::4]\n",
    "\n",
    "print()\n",
    "\n",
    "Par = {}\n",
    "# Par['nt'] = 100 \n",
    "Par['nx'] = traj_train.shape[2]\n",
    "Par['ny'] = traj_train.shape[3]\n",
    "Par['nf'] = 1\n",
    "Par['lb'] = 1\n",
    "Par['lf'] = 51 \n",
    "# Par['temp'] = Par['nt'] - Par['lb'] - Par['lf'] + 2\n",
    "\n",
    "Par['num_epochs'] = 500\n",
    "\n",
    "print('\\nTrain Dataset')\n",
    "x_train, y_train, t_train = preprocess(traj_train, Par)\n",
    "print('\\nValidation Dataset')\n",
    "x_val, y_val, t_val  = preprocess(traj_val, Par)\n",
    "print('\\nTest Dataset')\n",
    "x_test, y_test, t_test  = preprocess(traj_test, Par)\n",
    "\n",
    "t_min = np.min(t_train)\n",
    "t_max = np.max(t_train)\n",
    "\n",
    "Par['inp_shift'] = np.mean(x_train) \n",
    "Par['inp_scale'] = np.std(x_train)\n",
    "Par['out_shift'] = np.mean(y_train)\n",
    "Par['out_scale'] = np.std(y_train)\n",
    "Par['t_shift']   = t_min\n",
    "Par['t_scale']   = t_max - t_min\n",
    "\n",
    "Par['eta']   = 0.1\n",
    "Par['gamma'] = 0.99\n",
    "\n",
    "Par['Lambda_max'] = Par['eta']/(1 - Par['gamma'])\n",
    "\n",
    "Lambda = np.ones(y_train.shape, dtype=np.float32)*Par['Lambda_max']/2.0\n",
    "print(\"Lambda: \", Lambda.shape)\n",
    "\n",
    "inp_normalizer = Normalizer(Par['inp_shift'], Par['inp_scale'])\n",
    "out_normalizer = Normalizer(Par['out_shift'], Par['out_scale'])\n",
    "\n",
    "Par['model'] = 'FNO'\n",
    "\n",
    "with open('Par.pkl', 'wb') as f:\n",
    "    pickle.dump(Par, f)\n",
    "\n",
    "#########################\n",
    "\n",
    "# Create custom datasets\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "t_train_tensor = torch.tensor(t_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "Lambda_tensor = torch.tensor(Lambda, dtype=torch.float32)\n",
    "\n",
    "x_val_tensor   = torch.tensor(x_val,   dtype=torch.float32)\n",
    "t_val_tensor   = torch.tensor(t_val,   dtype=torch.float32)\n",
    "y_val_tensor   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "\n",
    "x_test_tensor  = torch.tensor(x_test,  dtype=torch.float32)\n",
    "t_test_tensor  = torch.tensor(t_test,  dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "data_dict = {'x_train':x_train_tensor, 'x_val':x_val_tensor, 'x_test':x_test_tensor}\n",
    "data_dict = _preprocess_fno(data_dict, Par)\n",
    "\n",
    "x_train_tensor = torch.tensor(data_dict['x_train'].cpu().numpy(), dtype=torch.float32)\n",
    "x_val_tensor   = torch.tensor(data_dict['x_val'].cpu().numpy()  , dtype=torch.float32)\n",
    "x_test_tensor  = torch.tensor(data_dict['x_test'].cpu().numpy() , dtype=torch.float32)\n",
    "\n",
    "# train_dataset = YourDataset(x_train_tensor, y_train_tensor)\n",
    "# val_dataset = YourDataset(x_val_tensor, y_val_tensor)\n",
    "# test_dataset = YourDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define data loaders\n",
    "train_batch_size = 10\n",
    "val_batch_size   = 10\n",
    "test_batch_size  = 10\n",
    "# train_loader = DataLoader(train_dataset, batch_size=train_batch_size)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=val_batch_size)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121c949-bc46-4666-81df-d5388bb24074",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad88d6d-6b19-4fdb-96d7-cfe848585cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created FNO\n",
      "Loading model ...\n"
     ]
    }
   ],
   "source": [
    "# Initialize your Unet2D model\n",
    "if Par['model']=='FNO':\n",
    "    model = TFNO3d(12, 12, 12, hidden_channels=20, in_channels=4, out_channels=1).cuda()\n",
    "print('Created '+Par['model'])\n",
    "METHOD='logarithmic'\n",
    "print('Loading model ...')\n",
    "path_model = f'models/best_model_{METHOD}_{METHOD}.pt'\n",
    "model.load_state_dict(torch.load(path_model,weights_only=False))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = CustomLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242f9ec-0947-40b5-b130-3f3e9be5b2c6",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd837999-77e4-4b68-bb22-febf146bc8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 3.0454e-04\n"
     ]
    }
   ],
   "source": [
    "# Validation loop\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for start in range(0, x_val.shape[0]-1, val_batch_size):\n",
    "        end = start + val_batch_size\n",
    "        x = x_val_tensor[start:end]\n",
    "        y_true = y_val_tensor[start:end]\n",
    "        x = inp_normalizer.normalize(x)\n",
    "        y_pred = out_normalizer.renormalize(model(x.to(device))[:,0]) \n",
    "        loss, _= criterion(y_pred, y_true.to(device), Par)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "val_loss /= int(y_val.shape[0]/val_batch_size)\n",
    "print(f'Val Loss: {val_loss:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0303665-3e91-42b6-9623-4079e922001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.5704e-04\n",
      "true:  torch.Size([100, 51, 64, 64])\n",
      "pred:  torch.Size([100, 51, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "y_true_ls = []\n",
    "y_pred_ls = []\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for start in range(0, x_test.shape[0]-1, test_batch_size):\n",
    "        end = start + test_batch_size\n",
    "        x = x_test_tensor[start:end]\n",
    "        y_true = y_test_tensor[start:end]\n",
    "        x = inp_normalizer.normalize(x)\n",
    "        y_pred = out_normalizer.renormalize(model(x.to(device))[:,0]) \n",
    "        loss, _= criterion(y_pred, y_true.to(device), Par)\n",
    "        y_true_ls.append(y_true)\n",
    "        y_pred_ls.append(y_pred)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= int(y_test.shape[0]/test_batch_size)\n",
    "print(f'Test Loss: {test_loss:.4e}')\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# test_loss = 0.0\n",
    "# with torch.no_grad():\n",
    "#     for x, y_true in test_loader:\n",
    "#         with autocast():\n",
    "#             y_pred = model(x.to(device), X_loc_test_tensor.to(device))\n",
    "#             loss = criterion(y_pred, y_true.to(device), Par).item() \n",
    "#         y_true_ls.append(y_true)\n",
    "#         y_pred_ls.append(y_pred)\n",
    "#         test_loss += loss \n",
    "# test_loss /= len(test_loader)\n",
    "# print(f'Test Loss: {test_loss:.4e}')\n",
    "\n",
    "Y_TRUE = torch.cat(y_true_ls, axis=0)\n",
    "Y_PRED = torch.cat(y_pred_ls, axis=0)\n",
    "\n",
    "print('true: ', Y_TRUE.shape)\n",
    "print('pred: ', Y_PRED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5abd0f3-d314-4744-9ee8-d941f956ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TRUE = Y_TRUE.detach().cpu().numpy()\n",
    "Y_PRED = Y_PRED.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd2820e-61a8-48bf-a278-babe3f533995",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Y_TRUE.npy\", Y_TRUE)\n",
    "np.save(\"Y_PRED.npy\", Y_PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db5ce72-48e5-4747-a45a-dfbd9fb575c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 51, 64, 64), (100, 51, 64, 64), 0.0003570364)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = np.load(\"Y_TRUE.npy\")\n",
    "pred = np.load(\"Y_PRED.npy\")\n",
    "true.shape, pred.shape, np.mean( (true -pred)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f2d3e-d549-4b15-be08-a2ef6c232957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23bf27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
